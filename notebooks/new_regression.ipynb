{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "import datetime\n",
    "\n",
    "from sklearn import neighbors\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "#'database_pipeline'\n",
    "\n",
    "class MongoDB():\n",
    "    def __init__(self,dbname):\n",
    "        self.client = MongoClient()\n",
    "        self.db = self.client[dbname]\n",
    "\n",
    "    def get_collection_name(self):\n",
    "        #Return all collection names\n",
    "        return self.db.list_collection_names()\n",
    "\n",
    "    def find(self, collection, what=dict(), _id=False, last=False):\n",
    "        #by default the function doesn't select the _id field\n",
    "        #retourne une list de dictionaire last=False\n",
    "        #retourne un dictionaire si last=True\n",
    "        if _id == False:\n",
    "            cursor = self.db[collection].find(what, {'_id': False})\n",
    "        else:\n",
    "            cursor = self.db[collection].find(what)\n",
    "\n",
    "        if last == True:\n",
    "            cursor = cursor.sort([(\"Time\", -1)]).limit(1)\n",
    "            return cursor[0]\n",
    "\n",
    "        return self.cursor_to_dict(cursor)\n",
    "\n",
    "    def find_all_last(self, what=dict(), _id=False, last=False):\n",
    "        d = dict()\n",
    "        for coll in self.get_collection_name():\n",
    "            if coll == \"users\":\n",
    "                continue\n",
    "            d[coll] = self.find(coll, what, _id, last)\n",
    "        return d\n",
    "\n",
    "    def insert_one(self, collection, item):\n",
    "        try:\n",
    "            #Insert l'item dans la base de données\n",
    "            self.db[collection].insert_one(item)\n",
    "            return 1\n",
    "        except:\n",
    "            print(\"Item non importé\")\n",
    "            return -1\n",
    "        \n",
    "    def insert_many(self, collection, liste):\n",
    "        try:\n",
    "            #Insert touts les items de la liste dans la base de données\n",
    "            #En une seule commande\n",
    "            self.db[collection].insert_many(liste)\n",
    "            return 1\n",
    "        except:\n",
    "            print(\"Liste d'item non importé\")\n",
    "            return -1\n",
    "\n",
    "    def cursor_to_dict(self, cursor):\n",
    "        l = list()\n",
    "        for i in cursor:\n",
    "            l.append(i)\n",
    "        return l\n",
    "\n",
    "    def get_keys(self, collection):\n",
    "        #Return all field name of a collection\n",
    "        map = Code(\"function() { for (var key in this) { emit(key, null); } }\")\n",
    "        reduce = Code(\"function(key, stuff) { return null; }\")\n",
    "        result = self.db[collection].map_reduce(map, reduce, \"myresults\")\n",
    "        return result.distinct('_id')\n",
    "\n",
    "#docs = list(self.db[collec_pipe_name].find().sort([('Time', -1)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_data(path):\n",
    "    '''\n",
    "        Ouvre et lis le fichier passer en parmètre, reconnais seulement les types de\n",
    "        fichier supportés par pandas : CSV, JSON, HTML, Local clipboard, MS Excel,\n",
    "        HDF5 Format, feather Format, Parquet Format, Msgpack, Stata, SAS, Python Pickle\n",
    "        Format, SQL, Google Big Query. Retourne les données lu.\n",
    "\n",
    "        :params:\n",
    "            path: path of the file\n",
    "\n",
    "        :type params:\n",
    "            path: string\n",
    "\n",
    "        :return: object containing the data loaded in memory, or return -1 if type\n",
    "                 not recognize.\n",
    "    '''\n",
    "    #On récupère le nom de l'extension du fichier\n",
    "    type = path.split(\".\")[-1]\n",
    "    #Selection de la bonne fonction de pandas à utiliser\n",
    "    func_to_call = 'read_{}'.format(type)\n",
    "\n",
    "    #Récupération de l'attribut de la fonction pour l'appeler\n",
    "    try :\n",
    "        func = getattr(pd, func_to_call)\n",
    "    except :\n",
    "        print(\"Pas de fonction disponible dans pandas pour lire les données\")\n",
    "        return -1\n",
    "\n",
    "    #Lecture des données\n",
    "    try :\n",
    "        return func(path)\n",
    "    except :\n",
    "        print(\"Incorrect path\")\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descript_df(dataframe):\n",
    "    '''\n",
    "        Permet de faire une description rapide du dataframe de sortie. Retourne une\n",
    "        description rapide des données.\n",
    "\n",
    "        :params:\n",
    "            dataframe: de faire une description rapide du dataframe de sortie\n",
    "\n",
    "        :type params:\n",
    "            dataframe: pandas.dataframe\n",
    "\n",
    "        :return: description rapide des données\n",
    "        :rtype: string\n",
    "    '''\n",
    "    print('Matrice de corrélation : \\n')\n",
    "    corr = dataframe.corr()\n",
    "    corr_color = plt.matshow(corr, cmap=plt.cm.Reds)\n",
    "\n",
    "    # Pour chaque colonne, montrer la répartition des valeurs (vérifier les valeurs aberrantes)\n",
    "    # Kde et Histogramme\n",
    "    i = 1\n",
    "    for column in dataframe:\n",
    "        i += 1\n",
    "        plt.figure(i, figsize=(15,3))\n",
    "        plt.subplot(121)\n",
    "        dataframe[column].plot.kde()\n",
    "        plt.title('Répartition de ' + column + ' : ')\n",
    "        plt.subplot(122)\n",
    "        dataframe[column].hist()\n",
    "        plt.title('Histogramme de ' + column + ' : ')\n",
    "\n",
    "    display = corr\n",
    "    return display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def bootstrap(pipeline, data, features, target, n):\n",
    "    '''\n",
    "        Effectue un boostrap de la pipeline sur les données passées en paramètre.\n",
    "        \n",
    "        :params:\n",
    "            pipeline : pipeline\n",
    "            data : dataframe\n",
    "            features : colonnent à utiliser pour la régréssion\n",
    "            target : colonne à prédire\n",
    "            n : nombres boostrap à faire\n",
    "\n",
    "        :return:\n",
    "            pred : dictionnaire contenant les valeurs bootstrap sous forme de liste pour chaque echantillons.\n",
    "    '''\n",
    "    length = len(data)\n",
    "    keys = range(length)\n",
    "    pred = {key: list() for key in keys}\n",
    "\n",
    "    for b in range(n):\n",
    "        #Random choice\n",
    "        np.random.seed(b)\n",
    "        index = np.random.choice(range(length), int(length/0.7))\n",
    "        index_test = data.index.difference(index)\n",
    "        train = data.loc[index]\n",
    "        test = data.loc[index_test]\n",
    "\n",
    "        #Fit des données\n",
    "        pipeline.fit(train[features], train[target])\n",
    "\n",
    "        #Prédiction et score sur la base de test\n",
    "        for i, p in zip(index_test, pipeline.predict(test[features])):\n",
    "            pred[i].append(p[0])\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 176,
=======
   "execution_count": 36,
>>>>>>> c55ef267d026fe2e0ff1dd4c17b81846a76d2f6e
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def compute_regression(pipeline, df, features, target, n):\n",
    "    '''\n",
    "        Permet d'obtenir les résultats des indicateurs de performances d'une régression par crossvalidation, \n",
    "        et retourne ces derniers.\n",
    "\n",
    "        :params:\n",
    "            pipeline : object de type pipeline\n",
    "            df : tuple des bases d'apprentissage et de test\n",
    "            features : colonnent à utiliser pour la régréssion\n",
    "            target : colonne à prédire\n",
    "            n : nombre de bootstrap pour le calcul des intervalles de confiance\n",
    "            BDD : booléen, pour True les résultats sont stockés dans la BDD pour\n",
    "                  False ils ne sont pas sauvegardés\n",
    "        :return:\n",
    "            r2 : score R2\n",
    "            variance : variance gloable expliquée par le modèle\n",
    "            rmse : root mean squared error\n",
    "            intervalle_10 : une liste de 10 intervalles de confiances pris dans la list triés\n",
    "                            des intervalles de confiances.\n",
    "            intervalle_mean : moyenne de tous les intervalles de confiance\n",
    "    '''\n",
    "    \n",
    "    # Calcul interval de confiance par bootstrap\n",
    "    pred = bootstrap(pipeline, df, features, target, 200)\n",
    "    inter_every_x = [2 * np.std(pred[i]) for i in pred.keys()]\n",
    "\n",
    "    min_inter = min(inter_every_x)\n",
    "    max_inter = min(inter_every_x)\n",
    "    med_inter = np.median(inter_every_x)\n",
    "    \n",
    "    # Calcul de la variance globale expliqué, de r2 et du RMSE\n",
    "    # par Cross-Validation\n",
    "    scoring = {\"variance\" : \"explained_variance\",\n",
    "               \"r2\" : \"r2\", \n",
    "               \"mse\" : \"neg_mean_squared_error\"}\n",
    "    result = cross_validate(pipeline, data[features], data[target], cv=7, scoring=scoring)\n",
    "    variance = np.mean(result[\"test_variance\"])\n",
    "    r2 = np.mean(result[\"test_r2\"])\n",
    "    rmse = np.mean(np.sqrt(np.absolute(result[\"test_mse\"])))\n",
    "    \n",
<<<<<<< HEAD
    "    result = {\"R2\": r2, \"Variance\": variance, \"RMSE\": rmse, \"min_inter\" : min_inter, \"max_inter\" : max_inter, \"med_inter\" : med_inter}\n",
=======
    "    result = {\"r2\": r2, \"variance\": variance, \"rmse\": rmse, \"min_inter\" : min_inter, \"max_inter\" : max_inter, \"med_inter\": med_inter}\n",
>>>>>>> c55ef267d026fe2e0ff1dd4c17b81846a76d2f6e
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 177,
=======
   "execution_count": 37,
>>>>>>> c55ef267d026fe2e0ff1dd4c17b81846a76d2f6e
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_performance(pipeline, modele, df,  features, target, n, BDD=True):\n",
    "    '''\n",
    "        Permet d'appeler les bons indicateurs de performances et de récupérer\n",
    "        les informations utiles selon la pipeline passé en paramètre. Retourne les\n",
    "        performances associées.\n",
    "\n",
    "        :params:\n",
    "            pipeline : object de type pipeline\n",
    "            modele : type du modèle utilisé : régression/classification)\n",
    "            features : colonnent à utiliser pour la régréssion\n",
    "            target : colonne à prédire\n",
    "            n : nombre de bootstrap pour le calcul des intervalles de confiance\n",
    "            BDD : booléen, pour True les résultats sont stockés dans la BDD pour\n",
    "                  False ils ne sont pas sauvegardés\n",
    "\n",
    "        :type params:\n",
    "            bool_type_modele: boolean\n",
    "            base: tuple\n",
    "\n",
    "        :return: les performances des différents indicateurs et graphiques\n",
    "    '''\n",
    "    if (modele == \"regression\") :\n",
    "        print(\"Choix du type d'estimateur : Régression \\n\")       \n",
    "        result = compute_regression(pipeline, df, features, target, n)\n",
    "\n",
    "    elif(modele == \"classification\"):\n",
    "        print(\"Choix du type d'estimateur : Classification \\n\")\n",
    "        result = compute_classification(pipeline, df)\n",
    "    \n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "    if BDD == True:\n",
    "        result['Time'] = datetime.datetime.now()\n",
    "        result[\"_id\"] = pipeline.name + \".\" + str(result['Time'])\n",
    "        mongo = MongoDB(\"database_pipeline\")\n",
    "        mongo.insert_one(pipeline.name, result)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 178,
=======
   "execution_count": 38,
>>>>>>> c55ef267d026fe2e0ff1dd4c17b81846a76d2f6e
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_metadata_property(obj, name):\n",
    "    '''\n",
    "        Permet d'ajouter un atribut à un objet existant\n",
    "    '''\n",
    "    setattr(obj, \"name\", name)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 179,
=======
   "execution_count": 39,
>>>>>>> c55ef267d026fe2e0ff1dd4c17b81846a76d2f6e
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline à utiliser\n",
    "\n",
    "data = pd.read_csv(\"./../data/headbrain.csv\", skiprows=1, \n",
    "                      names=['gender','age_range' , 'head_size', 'brain_weight'])\n",
    "Y = data.iloc[:,0:3]\n",
    "\n",
    "# Création de la pipeline\n",
    "pipe_test = Pipeline([\n",
    "    ('features', StandardScaler()),\n",
    "    ('estimator', neighbors.KNeighborsRegressor())   \n",
    "])\n",
    "\n",
    "# Ajout d'un nom à la pipeline\n",
    "add_metadata_property(pipe_test, 'pipe_elias')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 180,
=======
   "execution_count": 40,
>>>>>>> c55ef267d026fe2e0ff1dd4c17b81846a76d2f6e
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "def get_all_pipes_names(path):\n",
    "    '''\n",
    "        Liste  tous les fichiers contenus dans le dossier passé en paramètre.\n",
    "        \n",
    "        :return: liste contenant les noms des fichiers\n",
    "    '''\n",
    "    l = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "    try :\n",
    "        l.remove(\"default.py\")\n",
    "    except:\n",
    "        pass\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 181,
=======
   "execution_count": 41,
>>>>>>> c55ef267d026fe2e0ff1dd4c17b81846a76d2f6e
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IrisExploration.ipynb',\n",
       " 'Mi-Avancement Projet.ipynb',\n",
       " 'pipe_test_4.py',\n",
       " 'regression.ipynb',\n",
       " 'pipe_test_1.py',\n",
       " 'pipe_test_2.py',\n",
       " 'pipe_test_3.py']"
      ]
     },
<<<<<<< HEAD
     "execution_count": 181,
=======
     "execution_count": 41,
>>>>>>> c55ef267d026fe2e0ff1dd4c17b81846a76d2f6e
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_all_pipes_names(\"./\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 182,
=======
   "execution_count": 42,
>>>>>>> c55ef267d026fe2e0ff1dd4c17b81846a76d2f6e
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "\n",
    "def get_pipelines(path, pipe_file):\n",
    "    '''\n",
    "        Charge la pipeline dont le nom du fichier est passé en paramètre. Et lui\n",
    "        rajoute un atribut name contenant son nom.\n",
    "\n",
    "        :params:\n",
    "            path: lien du dossier\n",
    "            pipe_file : nom du fichier de la pipeline.\n",
    "\n",
    "        :type params:\n",
    "            pipe_name: str\n",
    "\n",
    "        :return: object contenant la pipeline\n",
    "    '''\n",
    "    spec = importlib.util.spec_from_file_location(\"module.name\", path+pipe_file)\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(module)\n",
    "\n",
    "    #import de la pipeline\n",
    "    pipeline = module.pipeline\n",
    "\n",
    "    # Ajout d'un nom à la pipeline\n",
    "    add_metadata_property(pipeline, pipe_file[:-3])\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     gender  age_range  head_size  brain_weight\n",
      "0         1          1       4512          1530\n",
      "1         1          1       3738          1297\n",
      "2         1          1       4261          1335\n",
      "3         1          1       3777          1282\n",
      "4         1          1       4177          1590\n",
      "5         1          1       3585          1300\n",
      "6         1          1       3785          1400\n",
      "7         1          1       3559          1255\n",
      "8         1          1       3613          1355\n",
      "9         1          1       3982          1375\n",
      "10        1          1       3443          1340\n",
      "11        1          1       3993          1380\n",
      "12        1          1       3640          1355\n",
      "13        1          1       4208          1522\n",
      "14        1          1       3832          1208\n",
      "15        1          1       3876          1405\n",
      "16        1          1       3497          1358\n",
      "17        1          1       3466          1292\n",
      "18        1          1       3095          1340\n",
      "19        1          1       4424          1400\n",
      "20        1          1       3878          1357\n",
      "21        1          1       4046          1287\n",
      "22        1          1       3804          1275\n",
      "23        1          1       3710          1270\n",
      "24        1          1       4747          1635\n",
      "25        1          1       4423          1505\n",
      "26        1          1       4036          1490\n",
      "27        1          1       4022          1485\n",
      "28        1          1       3454          1310\n",
      "29        1          1       4175          1420\n",
      "..      ...        ...        ...           ...\n",
      "207       2          2       3995          1296\n",
      "208       2          2       3318          1175\n",
      "209       2          2       2720           955\n",
      "210       2          2       2937          1070\n",
      "211       2          2       3580          1320\n",
      "212       2          2       2939          1060\n",
      "213       2          2       2989          1130\n",
      "214       2          2       3586          1250\n",
      "215       2          2       3156          1225\n",
      "216       2          2       3246          1180\n",
      "217       2          2       3170          1178\n",
      "218       2          2       3268          1142\n",
      "219       2          2       3389          1130\n",
      "220       2          2       3381          1185\n",
      "221       2          2       2864          1012\n",
      "222       2          2       3740          1280\n",
      "223       2          2       3479          1103\n",
      "224       2          2       3647          1408\n",
      "225       2          2       3716          1300\n",
      "226       2          2       3284          1246\n",
      "227       2          2       4204          1380\n",
      "228       2          2       3735          1350\n",
      "229       2          2       3218          1060\n",
      "230       2          2       3685          1350\n",
      "231       2          2       3704          1220\n",
      "232       2          2       3214          1110\n",
      "233       2          2       3394          1215\n",
      "234       2          2       3233          1104\n",
      "235       2          2       3352          1170\n",
      "236       2          2       3391          1120\n",
      "\n",
      "[237 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "pipeline = get_pipelines(\"./\", \"pipe_test_1.py\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
=======
   "execution_count": 43,
>>>>>>> c55ef267d026fe2e0ff1dd4c17b81846a76d2f6e
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample = data.sample(100)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 185,
=======
   "execution_count": 44,
>>>>>>> c55ef267d026fe2e0ff1dd4c17b81846a76d2f6e
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choix du type d'estimateur : Régression \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "{'R2': 0.3481668714809448,\n",
       " 'Variance': 0.3952789773404247,\n",
       " 'RMSE': 82.0436558084634,\n",
       " 'min_inter': 12.839143407582556,\n",
       " 'max_inter': 12.839143407582556,\n",
       " 'med_inter': 56.862267818714464,\n",
       " 'Time': datetime.datetime(2019, 4, 8, 17, 23, 18, 973593),\n",
       " '_id': 'pipe_test_1.2019-04-08 17:23:18.973593'}"
      ]
     },
     "execution_count": 185,
=======
       "{'r2': 0.3481668714809448,\n",
       " 'variance': 0.3952789773404247,\n",
       " 'rmse': 82.0436558084634,\n",
       " 'min_inter': 12.839143407582556,\n",
       " 'max_inter': 12.839143407582556,\n",
       " 'med_inter': 56.862267818714464,\n",
       " 'Time': datetime.datetime(2019, 4, 8, 16, 17, 51, 505378),\n",
       " '_id': 'pipe_test.2019-04-08 16:17:51.505378'}"
      ]
     },
     "execution_count": 44,
>>>>>>> c55ef267d026fe2e0ff1dd4c17b81846a76d2f6e
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_performance(pipeline, \"regression\", data, [\"age_range\", \"head_size\"], [\"brain_weight\"], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = [5, 4]\n",
    "min(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
